import re
import ast
from typing import List, Dict, Tuple
import logging

logger = logging.getLogger(__name__)


class AdvancedSecurityScanner:
    def __init__(self):
        self.owasp_patterns = {
            'sql_injection': {
                'patterns': [
                    r'SELECT.*FROM.*WHERE.*=.*\+',
                    r'query\s*=.*\+.*request\.',
                    r'cursor\.execute\s*\(.*\+',
                    r'\.format\s*\(.*request\.',
                    r'%\s*\(.*request\.'
                ],
                'severity': 'high',
                'description': 'Potential SQL injection vulnerability'
            },
            'hardcoded_secrets': {
                'patterns': [
                    r'password\s*=\s*["\'][^"\']{8,}["\']',
                    r'api_key\s*=\s*["\'][A-Za-z0-9]{20,}["\']',
                    r'secret\s*=\s*["\'][^"\']{10,}["\']',
                    r'token\s*=\s*["\'][A-Za-z0-9]{20,}["\']',
                    r'key\s*=\s*["\'][A-Za-z0-9]{16,}["\']'
                ],
                'severity': 'high',
                'description': 'Hardcoded credentials detected'
            },
            'xss_vulnerability': {
                'patterns': [
                    r'innerHTML\s*=.*request\.',
                    r'document\.write\s*\(.*request\.',
                    r'\.html\s*\(.*request\.',
                    r'render_template_string\s*\(.*request\.'
                ],
                'severity': 'medium',
                'description': 'Potential XSS vulnerability'
            },
            'path_traversal': {
                'patterns': [
                    r'open\s*\(.*\+.*request\.',
                    r'file\s*=.*request\..*\+',
                    r'\.\.\/.*request\.',
                    r'os\.path\.join\s*\(.*request\.'
                ],
                'severity': 'medium',
                'description': 'Potential path traversal vulnerability'
            },
            'command_injection': {
                'patterns': [
                    r'os\.system\s*\(.*request\.',
                    r'subprocess\.(call|run|Popen)\s*\(.*request\.',
                    r'eval\s*\(.*request\.',
                    r'exec\s*\(.*request\.'
                ],
                'severity': 'high',
                'description': 'Potential command injection vulnerability'
            },
            'insecure_random': {
                'patterns': [
                    r'random\.random\s*\(',
                    r'random\.choice\s*\(',
                    r'Math\.random\s*\('
                ],
                'severity': 'low',
                'description': 'Use of cryptographically insecure random number generator'
            }
        }

    @cached_analysis("security_scan")
    def scan_for_vulnerabilities(self, file_content: str, filename: str) -> List[Dict]:
        """Scan code for security vulnerabilities with caching"""
        print(f"ðŸ”’ Running security scan for {filename} (cache miss)")

        vulnerabilities = []

        # Pattern-based scanning
        pattern_vulns = self._scan_patterns(file_content, filename)
        vulnerabilities.extend(pattern_vulns)

        # AST-based scanning for Python files
        if filename.endswith('.py'):
            ast_vulns = self._scan_with_ast(file_content, filename)
            vulnerabilities.extend(ast_vulns)

        return vulnerabilities

    def _scan_patterns(self, content: str, filename: str) -> List[Dict]:
        """Scan using regex patterns"""
        vulnerabilities = []

        for vuln_type, vuln_info in self.owasp_patterns.items():
            for pattern in vuln_info['patterns']:
                matches = re.finditer(
                    pattern, content, re.IGNORECASE | re.MULTILINE)
                for match in matches:
                    line_num = content[:match.start()].count('\n') + 1
                    vulnerabilities.append({
                        'type': vuln_type,
                        'severity': vuln_info['severity'],
                        'description': vuln_info['description'],
                        'line': line_num,
                        'code_snippet': match.group(0),
                        'filename': filename,
                        'recommendation': self._get_recommendation(vuln_type)
                    })

        return vulnerabilities

    def _scan_with_ast(self, content: str, filename: str) -> List[Dict]:
        """AST-based security scanning for Python files"""
        vulnerabilities = []

        try:
            tree = ast.parse(content)
            visitor = SecurityASTVisitor(filename)
            visitor.visit(tree)
            vulnerabilities.extend(visitor.vulnerabilities)
        except SyntaxError:
            logger.warning(f"Could not parse {filename} for AST analysis")
        except Exception as e:
            logger.error(f"Error in AST analysis for {filename}: {e}")

        return vulnerabilities

    def _get_recommendation(self, vuln_type: str) -> str:
        """Get security recommendation for vulnerability type"""
        recommendations = {
            'sql_injection': 'Use parameterized queries or prepared statements',
            'hardcoded_secrets': 'Store secrets in environment variables or secure vaults',
            'xss_vulnerability': 'Sanitize user input and use template escaping',
            'path_traversal': 'Validate and sanitize file paths, use allowlists',
            'command_injection': 'Avoid dynamic command execution, use safe alternatives',
            'insecure_random': 'Use cryptographically secure random generators (e.g., secrets module)'
        }
        return recommendations.get(vuln_type, 'Review code for security best practices')


class SecurityASTVisitor(ast.NodeVisitor):
    """AST visitor for detecting security issues in Python code"""

    def __init__(self, filename: str):
        self.filename = filename
        self.vulnerabilities = []
        self.current_line = 1

    def visit_Call(self, node):
        """Check function calls for security issues"""
        if isinstance(node.func, ast.Name):
            func_name = node.func.id

            # Check for dangerous functions
            if func_name in ['eval', 'exec']:
                self.vulnerabilities.append({
                    'type': 'dangerous_function',
                    'severity': 'high',
                    'description': f'Use of dangerous function: {func_name}',
                    'line': node.lineno,
                    'filename': self.filename,
                    'recommendation': 'Avoid using eval() and exec() with untrusted input'
                })

        elif isinstance(node.func, ast.Attribute):
            # Check for dangerous method calls
            if hasattr(node.func, 'attr'):
                if node.func.attr in ['system', 'popen']:
                    self.vulnerabilities.append({
                        'type': 'system_call',
                        'severity': 'high',
                        'description': f'Use of system call: {node.func.attr}',
                        'line': node.lineno,
                        'filename': self.filename,
                        'recommendation': 'Use subprocess with proper input validation'
                    })

        self.generic_visit(node)

    def visit_Import(self, node):
        """Check imports for potentially dangerous modules"""
        for alias in node.names:
            if alias.name in ['pickle', 'marshal']:
                self.vulnerabilities.append({
                    'type': 'insecure_deserialization',
                    'severity': 'medium',
                    'description': f'Import of potentially unsafe module: {alias.name}',
                    'line': node.lineno,
                    'filename': self.filename,
                    'recommendation': 'Be cautious with pickle/marshal - only deserialize trusted data'
                })

        self.generic_visit(node)
